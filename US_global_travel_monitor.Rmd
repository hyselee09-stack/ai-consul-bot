---
title: "US Global Travel Advisory Monitor (HTML Scraping)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require("pacman")) install.packages("pacman")
# Use 'rvest' for web scraping instead of 'tidyRSS'
pacman::p_load(rvest, tidyverse, telegram.bot, lubridate, stringr, readr)


# Retrieve secrets from GitHub
TELEGRAM_BOT_TOKEN <- Sys.getenv("TELEGRAM_BOT_TOKEN")
MY_CHAT_ID         <- Sys.getenv("MY_CHAT_ID")
bot <- Bot(token = TELEGRAM_BOT_TOKEN)


# Helper function for logging
log_msg <- function(msg) {
  message(paste0("[", Sys.time(), "] ", msg))
}

log_msg("üåç [Global Watch] Starting Travel Advisory Scan...")

# [Target] The main HTML page containing the table of all countries
target_url <- "[https://travel.state.gov/content/travel/en/traveladvisories/traveladvisories.html-/](https://travel.state.gov/content/travel/en/traveladvisories/traveladvisories.html-/)"
csv_file <- "travel_status_memory.csv"

# Function to scrape the HTML table directly
scrape_travel_table <- function() {
  tryCatch({
    # 1. Fetch the webpage
    # (rvest handles simple scraping well; usually bypasses basic RSS blocks)
    page <- read_html(target_url)
    
    # 2. Extract the table
    # Look for the <table> tag inside the page
    raw_table <- page %>% 
      html_element("table") %>% 
      html_table()
    
    # 3. Clean and Process Data
    clean_data <- raw_table %>%
      select(Advisory, Level, Date) %>% # Select relevant columns
      rename(
        Country = Advisory,
        Level_Text = Level,
        Date_Str = Date
      ) %>%
      mutate(
        # Remove " Travel Advisory" from the country name
        Country = str_remove(Country, " Travel Advisory"),
        # Extract just the level number (e.g., "Level 1" -> 1)
        Level_Num = as.numeric(str_extract(Level_Text, "[0-9]")),
        # Parse date (Format: October 20, 2023)
        Pub_Date = mdy(Date_Str),
        # Use the main URL as the link since the table lacks individual links
        Link = target_url
      ) %>%
      filter(!is.na(Country) & !is.na(Level_Num))
    
    return(clean_data)
    
  }, error = function(e) {
    log_msg(paste("‚ö†Ô∏è Scraping Failed:", e$message))
    return(NULL)
  })
}

# --- Execute Main Logic ---

current_data <- scrape_travel_table()

if (!is.null(current_data) && nrow(current_data) > 0) {
  log_msg(paste("‚úÖ Data fetch successful! Checked", nrow(current_data), "countries."))
  
  # Check if previous history exists
  if (file.exists(csv_file)) {
    past_data <- read_csv(csv_file, show_col_types = FALSE)
    
    # Compare old vs new data based on Country name
    comparison <- current_data %>%
      inner_join(past_data, by = "Country", suffix = c("_new", "_old")) %>%
      filter(Level_Num_new != Level_Num_old) 
      
    # If there are changes
    if (nrow(comparison) > 0) {
      for(i in 1:nrow(comparison)) {
        row <- comparison[i, ]
        
        # Determine status (Worsened or Improved)
        if (row$Level_Num_new > row$Level_Num_old) {
           emoji <- "üìâ (Risk Increase)"
        } else {
           emoji <- "üìà (Improved)"
        }
        
        # Compose Alert Message
        msg <- paste0(
          "üá∫üá∏ [Travel Advisory Update]\n\n",
          "üè≥Ô∏è Country: ", row$Country, "\n",
          emoji, " Level: Lv.", row$Level_Num_old, " ‚û°Ô∏è Lv.", row$Level_Num_new, "\n",
          "üìÖ Date: ", row$Date_Str_new, "\n",
          "üîó Link: ", target_url
        )
        
        # Send Telegram Message
        try(bot$sendMessage(chat_id = MY_CHAT_ID, text = msg))
        Sys.sleep(1) # Sleep to prevent flooding
      }
      log_msg(paste("‚úÖ Sent alerts for", nrow(comparison), "changed countries."))
    } else {
      log_msg("-> No changes in safety levels.")
    }
  } else {
    log_msg("-> [Init] First run. Creating initial data file.")
    try(bot$sendMessage(chat_id = MY_CHAT_ID, text = "‚úÖ [Travel Monitor] Initial data collection complete."))
  }
  
  # Save current data to CSV for next run
  write_csv(current_data, csv_file)
  log_msg(paste("üíæ Data saved to:", csv_file))

} else {
  log_msg("‚ùå Final Failure: Could not fetch data. File will not be updated.")
}
